{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import ast\n",
    "import csv\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv,find_dotenv\n",
    "load_dotenv(find_dotenv())\n",
    "from utils import Static_dataGen, Dynamic_dataGen, Bonus_dataGen, Preprocessing\n",
    "\n",
    "key = os.environ.get(\"OPEN_AI_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Static Dataset Creation\n",
    "Aim: To generate a set of query-output pairs using the original set of 9 tools\n",
    "\n",
    "Method: Sampling of 3-4 tools for query generation in multiple iterations, followed by passing the complete queries and tool list for output generation in the completion agent. Data cleaning by code and manual intervention for final dataset creation.\n",
    "\n",
    "Previous Method: Similar to method 2, except that both query-outputs were generated together in the same agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "staticDatagen = Static_dataGen(key)\n",
    "\n",
    "no_of_StaticQuery_CompletionPairs2beGen = 10\n",
    "\n",
    "data_dict = staticDatagen.genQuery(no_of_StaticQuery_CompletionPairs2beGen)\n",
    "\n",
    "field_names= ['Query','Output']\n",
    "\n",
    "with open('./datasets/Generated/saveStaticdataset.csv', 'w') as csv_file:  \n",
    "    csv_writer = csv.DictWriter(csv_file, fieldnames=data_dict[0].keys())\n",
    "    csv_writer.writeheader()\n",
    "    csv_writer.writerows(data_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dynamic Dataset Creation\n",
    "Aim: To generate a dynamic toolset, and combining them with the original toolset to obtain a set of query-output pairs\n",
    "\n",
    "Method (Dynamic Toolset Creation): Sampling of 4 tools from the original toolset in multiple iterations, and generating similar tools. Experimenting with prompt and temperature to modify tools.\n",
    "\n",
    "Method (Query-Output Pair Generation): Passing random 10 tools along with the original 9 at a time, the model has the liberty to select any number of tools from this for query generation. Using this query list in the completion agent where it generates the relevant outputs. The query list is cleaned by code and manual intervention before passing to the second agent, and a similar process is followed for the final CSV creation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dynamicDatagen = Dynamic_dataGen(key)\n",
    "\n",
    "no_of_newTool2beAdded = 10\n",
    "\n",
    "no_of_DynamicQuery_CompletionPairs2beGen = 10\n",
    "\n",
    "dynamicDatagen.genDynamicTools(no_of_newTool2beAdded)\n",
    "\n",
    "data_dict = dynamicDatagen.genDynamicQueryOutputPair(no_of_DynamicQuery_CompletionPairs2beGen)\n",
    "\n",
    "field_names= ['Added_Tools','Query','Output']\n",
    "\n",
    "with open('./datasets/Generated/saveDynamicData.csv', 'w') as csvfile:\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=field_names)\n",
    "    writer.writeheader()\n",
    "    writer.writerows(data_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bonus Dataset Creation\n",
    "Aim: To generate a set of query-output pairs which involves usage of conditional and iterative operators\n",
    "\n",
    "Method: Manually creating a list of 5 such query-output pairs, feeding these examples along with a list of a few relevant dynamic tools combined with the original toolset in the query-generating agent, and finally passing this list of queries in the completion agent. At every step of output from the model, the data is cleaned before saving and passing to the further agents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "bonusDatagen = Bonus_dataGen(key)\n",
    "\n",
    "no_of_BonusQuery_CompletionPairs2beGen = 10\n",
    "\n",
    "data_dict = bonusDatagen.genBonusQueryOutputPair(no_of_BonusQuery_CompletionPairs2beGen)\n",
    "\n",
    "field_names= ['Query','Output']\n",
    "\n",
    "with open('./datasets/Generated/saveBonusData.csv', 'w') as csvfile:\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=field_names)\n",
    "    writer.writeheader()\n",
    "    writer.writerows(data_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Static Dataset Reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Query</th>\n",
       "      <th>Output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Summarize issues similar to don:core:dvrv-us-1...</td>\n",
       "      <td>var_1 = get_similar_work_items(work_id=\"don:co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Summarize high severity tickets from the custo...</td>\n",
       "      <td>var_1 = search_object_by_name(query=\"UltimateC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What are my all issues in the triage stage und...</td>\n",
       "      <td>var_1 = who_am_i()\\nvar_2 = works_list(stage.n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>List all high severity tickets coming in from ...</td>\n",
       "      <td>var_1 = search_object_by_name(query=\"Cust123\")...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Given a customer meeting transcript \"T\", creat...</td>\n",
       "      <td>var_1 = create_actionable_tasks_from_text(text...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Query  \\\n",
       "0  Summarize issues similar to don:core:dvrv-us-1...   \n",
       "1  Summarize high severity tickets from the custo...   \n",
       "2  What are my all issues in the triage stage und...   \n",
       "3  List all high severity tickets coming in from ...   \n",
       "4  Given a customer meeting transcript \"T\", creat...   \n",
       "\n",
       "                                              Output  \n",
       "0  var_1 = get_similar_work_items(work_id=\"don:co...  \n",
       "1  var_1 = search_object_by_name(query=\"UltimateC...  \n",
       "2  var_1 = who_am_i()\\nvar_2 = works_list(stage.n...  \n",
       "3  var_1 = search_object_by_name(query=\"Cust123\")...  \n",
       "4  var_1 = create_actionable_tasks_from_text(text...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "static_df = pd.read_csv(\"./datasets/originals/static_dataset.csv\") \n",
    "promptForm = Preprocessing()\n",
    "\n",
    "static_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompt formation for P2 Pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "staticDictP2 = []\n",
    "for i, row in static_df.iterrows():\n",
    "    query = row['Query']\n",
    "    output = row['Output']\n",
    "    prompt = promptForm.prompt_p2_pipeline(query,output)\n",
    "    staticDictP2.append({'Prompt':prompt})\n",
    "\n",
    "field_names= ['Prompt']\n",
    "\n",
    "with open('./promptForm/StaticP2prompt.csv', 'w') as csvfile:\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=field_names)\n",
    "    writer.writeheader()\n",
    "    writer.writerows(staticDictP2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompt formation for P3 Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "staticDictP3 = []\n",
    "for i, row in static_df.iterrows():\n",
    "    query = row['Query']\n",
    "    output = row['Output']\n",
    "    prompt = promptForm.prompt_p3_pipeline(query,output)\n",
    "    staticDictP3.append({'Prompt':prompt})\n",
    "\n",
    "field_names = ['Prompt']\n",
    "\n",
    "with open('./promptForm/StaticP3prompt.csv', 'w') as csvfile:\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=field_names)\n",
    "    writer.writeheader()\n",
    "    writer.writerows(staticDictP3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dynamic Dataset Reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Added_Tools</th>\n",
       "      <th>Query</th>\n",
       "      <th>Output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['\\n def list_user_tasks(user_id, completed=Fa...</td>\n",
       "      <td>For user \"Tina\", list her tasks, filter work ...</td>\n",
       "      <td>var_1 = list_user_tasks(user_id=\"Tina\")\\nvar_2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['\\n \\n def list_user_tasks(user_id, completed...</td>\n",
       "      <td>Find the current sprint ID, list all tasks ass...</td>\n",
       "      <td>var_1 = get_sprint_id()\\nvar_2 = search_object...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['\\n \\n def list_user_tasks(user_id, completed...</td>\n",
       "      <td>Search for the user ID of \"ManagerMike,\" list ...</td>\n",
       "      <td>var_1 = search_object_by_name(query=\"ManagerMi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['\\n \\n def list_user_tasks(user_id, completed...</td>\n",
       "      <td>Use the ID of the current user, list all tasks...</td>\n",
       "      <td>var_1 = who_am_i()\\nvar_2 = list_user_tasks(us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['\\n \\n def list_user_tasks(user_id, completed...</td>\n",
       "      <td>Retrieve the ID of the current sprint, list al...</td>\n",
       "      <td>var_1 = get_sprint_id()\\nvar_2 = search_object...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Added_Tools  \\\n",
       "0  ['\\n def list_user_tasks(user_id, completed=Fa...   \n",
       "1  ['\\n \\n def list_user_tasks(user_id, completed...   \n",
       "2  ['\\n \\n def list_user_tasks(user_id, completed...   \n",
       "3  ['\\n \\n def list_user_tasks(user_id, completed...   \n",
       "4  ['\\n \\n def list_user_tasks(user_id, completed...   \n",
       "\n",
       "                                               Query  \\\n",
       "0   For user \"Tina\", list her tasks, filter work ...   \n",
       "1  Find the current sprint ID, list all tasks ass...   \n",
       "2  Search for the user ID of \"ManagerMike,\" list ...   \n",
       "3  Use the ID of the current user, list all tasks...   \n",
       "4  Retrieve the ID of the current sprint, list al...   \n",
       "\n",
       "                                              Output  \n",
       "0  var_1 = list_user_tasks(user_id=\"Tina\")\\nvar_2...  \n",
       "1  var_1 = get_sprint_id()\\nvar_2 = search_object...  \n",
       "2  var_1 = search_object_by_name(query=\"ManagerMi...  \n",
       "3  var_1 = who_am_i()\\nvar_2 = list_user_tasks(us...  \n",
       "4  var_1 = get_sprint_id()\\nvar_2 = search_object...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dynamic_df = pd.read_csv(\"./datasets/originals/dynamic_dataset.csv\") \n",
    "promptForm = Preprocessing()\n",
    "\n",
    "dynamic_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompt formation for P2 Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dynamicDictP2 = []\n",
    "for i, row in dynamic_df.iterrows():\n",
    "    query = row['Query']\n",
    "    output = row['Output']\n",
    "    additional_tools = ast.literal_eval(row['Added_Tools'].replace(\"['\", \"['''\").replace(\"']\", \"''']\"))\n",
    "    prompt = promptForm.prompt_p2_pipeline(query,output,additional_tools)\n",
    "    dynamicDictP2.append({'Prompt':prompt})\n",
    "\n",
    "field_names= ['Prompt']\n",
    "\n",
    "with open('./promptForm/DynamicP2prompt.csv', 'w') as csvfile:\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=field_names)\n",
    "    writer.writeheader()\n",
    "    writer.writerows(dynamicDictP2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompt formation for P3 Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dynamicDictP3 = []\n",
    "for i, row in dynamic_df.iterrows():\n",
    "    query = row['Query']\n",
    "    output = row['Output']\n",
    "    additional_tools = ast.literal_eval(row['Added_Tools'].replace(\"['\", \"['''\").replace(\"']\", \"''']\"))\n",
    "    prompt = promptForm.prompt_p3_pipeline(query,output,additional_tools)\n",
    "    dynamicDictP3.append({'Prompt':prompt})\n",
    "\n",
    "field_names= ['Prompt']\n",
    "\n",
    "with open('./promptForm/DynamicP3prompt.csv', 'w') as csvfile:\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=field_names)\n",
    "    writer.writeheader()\n",
    "    writer.writerows(dynamicDictP3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bonus Dataset Reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Query</th>\n",
       "      <th>Output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Create tasks from the text \"WeeklyUpdate\" and ...</td>\n",
       "      <td>var_1 = who_am_i()\\nvar_2 = create_actionable_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Retrieve work items with type \"task\" and sever...</td>\n",
       "      <td>for loop_var in range(0,10):\\n    temp_1 = wor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Find work items with priority \"p1\" and type \"i...</td>\n",
       "      <td>var_1 = works_list(issue.priority=[\"p1\"], type...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Extract tasks from the text \"ReleaseNotes\", pr...</td>\n",
       "      <td>var_1 = create_actionable_tasks_from_text(text...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fetch tasks for user \"USER-999\", prioritize th...</td>\n",
       "      <td>for loop_var in range(0,2):\\n    temp_1 = fetc...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Query  \\\n",
       "0  Create tasks from the text \"WeeklyUpdate\" and ...   \n",
       "1  Retrieve work items with type \"task\" and sever...   \n",
       "2  Find work items with priority \"p1\" and type \"i...   \n",
       "3  Extract tasks from the text \"ReleaseNotes\", pr...   \n",
       "4  Fetch tasks for user \"USER-999\", prioritize th...   \n",
       "\n",
       "                                              Output  \n",
       "0  var_1 = who_am_i()\\nvar_2 = create_actionable_...  \n",
       "1  for loop_var in range(0,10):\\n    temp_1 = wor...  \n",
       "2  var_1 = works_list(issue.priority=[\"p1\"], type...  \n",
       "3  var_1 = create_actionable_tasks_from_text(text...  \n",
       "4  for loop_var in range(0,2):\\n    temp_1 = fetc...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bonus_df = pd.read_csv(\"./datasets/originals/bonus_dataset.csv\") \n",
    "promptForm = Preprocessing()\n",
    "\n",
    "bonus_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompt formation for P2 Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "bonusDictP2 = []\n",
    "for i, row in bonus_df.iterrows():\n",
    "    query = row['Query']\n",
    "    output = row['Output']\n",
    "    prompt = promptForm.prompt_p2_pipeline(query,output)\n",
    "    bonusDictP2.append({'Prompt':prompt})\n",
    "\n",
    "field_names= ['Prompt']\n",
    "\n",
    "with open('./promptForm/BonusP2prompt.csv', 'w') as csvfile:\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=field_names)\n",
    "    writer.writeheader()\n",
    "    writer.writerows(bonusDictP2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompt formation for P3 Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "bonusDictP3 = []\n",
    "for i, row in bonus_df.iterrows():\n",
    "    query = row['Query']\n",
    "    output = row['Output']\n",
    "    prompt = promptForm.prompt_p3_pipeline(query,output)\n",
    "    bonusDictP3.append({'Prompt':prompt})\n",
    "\n",
    "field_names= ['Prompt']\n",
    "\n",
    "with open('./promptForm/BonusP3prompt.csv', 'w') as csvfile:\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=field_names)\n",
    "    writer.writeheader()\n",
    "    writer.writerows(bonusDictP3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Validation Test For Static Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### P2 Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./promptForm/StaticP2prompt.csv\")\n",
    "\n",
    "train_df = df[0:1700]\n",
    "validation_df = df[1700:1900]\n",
    "test_df = df[1900:]\n",
    "\n",
    "train_df.to_csv(\"./finetuning_P2dataset/train.csv\", index=False)\n",
    "validation_df.to_csv(\"./finetuning_P2dataset/validation.csv\", index=False)\n",
    "test_df.to_csv(\"./finetuning_P2dataset/test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### P3 Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./promptForm/StaticP3prompt.csv\")\n",
    "\n",
    "train_df = df[0:1700]\n",
    "validation_df = df[1700:1900]\n",
    "test_df = df[1900:]\n",
    "\n",
    "train_df.to_csv(\"./finetuning_P3dataset/train.csv\", index=False)\n",
    "validation_df.to_csv(\"./finetuning_P3dataset/validation.csv\", index=False)\n",
    "test_df.to_csv(\"./finetuning_P3dataset/test.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev-rev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
